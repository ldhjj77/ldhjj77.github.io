<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: 파일생성 - Hexo</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hexo"><meta name="msapplication-TileImage" content="/img/diablo.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hexo"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Hexo"><meta property="og:url" content="https://ldhjj77.github.io/"><meta property="og:site_name" content="Hexo"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://ldhjj77.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://ldhjj77.github.io"},"headline":"Hexo","image":["https://ldhjj77.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"Hexo","logo":{"@type":"ImageObject","url":"https://ldhjj77.github.io/img/diablo.jpg"}},"description":""}</script><link rel="icon" href="/img/diablo.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/diablo.jpg" alt="Hexo" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">홈</a><a class="navbar-item" href="/archives">아카이브</a><a class="navbar-item" href="/categories">카테고리</a><a class="navbar-item" href="/tags">테그</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">파일생성</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-02T03:12:55.000Z" title="2021. 7. 2. 오후 12:12:55">2021-07-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-02T03:20:02.389Z" title="2021. 7. 2. 오후 12:20:02">2021-07-02</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a></span><span class="level-item">3 minutes read (About 424 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/07/02/A/A029_assignment/">A029-assignment</a></h1><div class="content"><p>사용 버전 - Python 3.9.5 64-bit</p>
<h3 id="네이버-IT-과학뉴스-3개의-제목과-링크-가져오기"><a href="#네이버-IT-과학뉴스-3개의-제목과-링크-가져오기" class="headerlink" title="네이버 IT/과학뉴스 3개의 제목과 링크 가져오기"></a>네이버 IT/과학뉴스 3개의 제목과 링크 가져오기</h3><h3 id="네이버-웹툰-배스트첼린지에-등록된-웹툰-제목과-평점-가져오기"><a href="#네이버-웹툰-배스트첼린지에-등록된-웹툰-제목과-평점-가져오기" class="headerlink" title="네이버 웹툰 배스트첼린지에 등록된 웹툰 제목과 평점 가져오기"></a>네이버 웹툰 배스트첼린지에 등록된 웹툰 제목과 평점 가져오기</h3><h3 id="크롬웹드라이브를-활용해-네이버-로그인-하기"><a href="#크롬웹드라이브를-활용해-네이버-로그인-하기" class="headerlink" title="크롬웹드라이브를 활용해 네이버 로그인 하기"></a>크롬웹드라이브를 활용해 네이버 로그인 하기</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">IT_news</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[IT/과학 뉴스]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;https://news.naver.com/&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    res.raise_for_status()</span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    news_list = soup.find(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;id&#x27;</span>:<span class="string">&#x27;section_it&#x27;</span>&#125;)</span><br><span class="line">    news_list1 = news_list.find_all(<span class="string">&#x27;li&#x27;</span>, limit=<span class="number">3</span>)</span><br><span class="line">    now = time.strftime(<span class="string">&#x27;%Y-%m-%d %H-%M&#x27;</span>, time.localtime(time.time()))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(news_list1):        </span><br><span class="line">        title = news.find(<span class="string">&#x27;a&#x27;</span>).get_text().strip()</span><br><span class="line">        link = news.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;. &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(index + <span class="number">1</span>, title))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;(  링크 : &#123;0&#125;  )&#x27;</span>.<span class="built_in">format</span>(link))</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: </span><br><span class="line">            f.write(<span class="string">&#x27;[IT/과학 뉴스] &#123;0&#125; : &#123;1&#125; \n\n&#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, title))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(<span class="string">&#x27;\n\n\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bestChallenge</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[bestChallenge]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;https://comic.naver.com/genre/bestChallenge.nhn&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    res.raise_for_status()</span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    now = time.strftime(<span class="string">&#x27;%Y-%m-%d %H-%M&#x27;</span>, time.localtime(time.time()))  </span><br><span class="line">    bast = soup.find_all(<span class="string">&#x27;dl&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;mainTodayGrade&#x27;</span>&#125;)</span><br><span class="line">    bast1 = soup.find(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;mainTodayBox&#x27;</span>&#125;)</span><br><span class="line">    bast2 = bast1.find_all(<span class="string">&#x27;h4&#x27;</span>)</span><br><span class="line">    i = [<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> toon, toon1, i1 <span class="keyword">in</span> <span class="built_in">zip</span>(bast2, bast, i):</span><br><span class="line">        title = toon.find(<span class="string">&#x27;a&#x27;</span>).get_text().strip()</span><br><span class="line">        star = toon1.find(<span class="string">&#x27;strong&#x27;</span>).get_text()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; &#123;0&#125;  제목 : &#123;1&#125;  (  평점 : &#123;2&#125;  ) &#x27;</span>.<span class="built_in">format</span>(i1, title, star))</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: </span><br><span class="line">            f.write(<span class="string">&#x27;[bestChallenge] &#123;0&#125; 제목 : &#123;1&#125; ( 평점 : &#123;2&#125; ) \n\n&#x27;</span>.<span class="built_in">format</span>(i1, title, star))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: </span><br><span class="line">        f.write(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">naver_login</span>():</span></span><br><span class="line">    naver = <span class="string">&#x27;https://www.naver.com/&#x27;</span></span><br><span class="line">    browser = webdriver.Chrome()</span><br><span class="line">    browser.get(naver)</span><br><span class="line"></span><br><span class="line">    browser.find_element_by_xpath(<span class="string">&#x27;//*[@id=&quot;account&quot;]/a&#x27;</span>).click()</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    browser.find_element_by_id(<span class="string">&#x27;id&#x27;</span>).send_keys(<span class="string">&#x27;naverid&#x27;</span>)</span><br><span class="line">    time.sleep(<span class="number">1</span>)  </span><br><span class="line">    browser.find_element_by_id(<span class="string">&#x27;pw&#x27;</span>).send_keys(<span class="string">&#x27;naverpw&#x27;</span>)</span><br><span class="line">    time.sleep(<span class="number">1</span>)  </span><br><span class="line">    browser.find_element_by_id(<span class="string">&#x27;log.login&#x27;</span>).click()</span><br><span class="line">    time.sleep(<span class="number">2</span>)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    IT_news()          </span><br><span class="line">    bestChallenge()</span><br><span class="line">    naver_login()</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-01T05:20:44.000Z" title="2021. 7. 1. 오후 2:20:44">2021-07-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-01T05:17:49.026Z" title="2021. 7. 1. 오후 2:17:49">2021-07-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a></span><span class="level-item">6 minutes read (About 826 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/07/01/A/A027_news/">A027_news</a></h1><div class="content"><p>사용 버전 - Python 3.9.5 64-bit</p>
<h1 id="텍스트-파일-생성후-뉴스-기록"><a href="#텍스트-파일-생성후-뉴스-기록" class="headerlink" title="텍스트 파일 생성후 뉴스 기록"></a>텍스트 파일 생성후 뉴스 기록</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">jtbc_news</span>():</span></span><br><span class="line">    url = <span class="string">&quot;https://news.jtbc.joins.com/default.aspx&quot;</span></span><br><span class="line">    res = urllib.request.urlopen(url)</span><br><span class="line">    source = res.read()</span><br><span class="line">    res.close()</span><br><span class="line">    soup = BeautifulSoup(source, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    soup = soup.find_all(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;feed_img&#x27;</span>&#125;, limit=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># print(soup)</span></span><br><span class="line">    now = time.strftime(<span class="string">&#x27;%Y-%m-%d %H-%M&#x27;</span>, time.localtime(time.time()))</span><br><span class="line">    <span class="comment"># print(now)</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">        f.write(<span class="string">&#x27;오늘의 주요 뉴스\n\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup):</span><br><span class="line">        data = news.find(<span class="string">&#x27;a&#x27;</span>).get_text()</span><br><span class="line">        link = news.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;jtbc 뉴스 &#123;0&#125; : &#123;1&#125; &#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; 링크 : &#123;0&#125; &#x27;</span>.<span class="built_in">format</span>(link))</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">            f.write(<span class="string">&#x27;jtbc_news &#123;0&#125; : &#123;1&#125; \n\n&#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">        f.write(<span class="string">&#x27;\n\n\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">psy_cardnews</span>():</span></span><br><span class="line">    url = <span class="string">&quot;http://www.psychiatricnews.net/news/articleList.html?sc_section_code=S1N23&amp;view_type=sm&quot;</span></span><br><span class="line">    res = urllib.request.urlopen(url)</span><br><span class="line">    source = res.read()</span><br><span class="line">    res.close()</span><br><span class="line">    soup = BeautifulSoup(source, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    soup = soup.find_all(<span class="string">&#x27;h4&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;titles&#x27;</span>&#125;, limit=<span class="number">10</span>)</span><br><span class="line">    now = time.strftime(<span class="string">&#x27;%Y-%m-%d %H-%M&#x27;</span>, time.localtime(time.time()))</span><br><span class="line">    <span class="comment"># print(soup)</span></span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup):</span><br><span class="line">        data = news.find(<span class="string">&#x27;a&#x27;</span>).get_text()</span><br><span class="line">        link = news.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;카드뉴스 &#123;0&#125; : &#123;1&#125; &#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; 링크 : &#123;0&#125; &#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;http://www.psychiatricnews.net&#x27;</span>+link))</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">            f.write(<span class="string">&#x27;psy_cardnews &#123;0&#125; : &#123;1&#125; \n\n&#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">        f.write(<span class="string">&#x27;\n\n\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sciencetimes</span>():</span></span><br><span class="line">    url = <span class="string">&quot;https://www.sciencetimes.co.kr/category/sci-tech/&quot;</span></span><br><span class="line">    res = urllib.request.urlopen(url)</span><br><span class="line">    source = res.read()</span><br><span class="line">    res.close()</span><br><span class="line">    soup = BeautifulSoup(source, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    soup = soup.find_all(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;board_cont&#x27;</span>&#125;, limit=<span class="number">9</span>)</span><br><span class="line">    now = time.strftime(<span class="string">&#x27;%Y-%m-%d %H-%M&#x27;</span>, time.localtime(time.time()))</span><br><span class="line">    <span class="comment"># print(soup)</span></span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup):</span><br><span class="line">        data = news.find(<span class="string">&#x27;strong&#x27;</span>).get_text()</span><br><span class="line">        link = news.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;과학 기술 &#123;0&#125; : &#123;1&#125; &#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; 링크 : &#123;0&#125; &#x27;</span>.<span class="built_in">format</span>(link))</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">            f.write(<span class="string">&#x27;sciencetimes &#123;0&#125; : &#123;1&#125; \n\n&#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">        f.write(<span class="string">&#x27;\n\n\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ilovepc</span>():</span></span><br><span class="line">    url = <span class="string">&quot;http://www.ilovepc.co.kr/news/articleList.html?sc_section_code=S1N1&amp;view_type=sm&quot;</span></span><br><span class="line">    res = urllib.request.urlopen(url)</span><br><span class="line">    source = res.read()</span><br><span class="line">    res.close()</span><br><span class="line">    soup = BeautifulSoup(source, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    soup = soup.find_all(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;list-titles&#x27;</span>&#125;, limit=<span class="number">8</span>)</span><br><span class="line">    now = time.strftime(<span class="string">&#x27;%Y-%m-%d %H-%M&#x27;</span>, time.localtime(time.time()))</span><br><span class="line">    <span class="comment"># print(soup)</span></span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup):</span><br><span class="line">        data = news.find(<span class="string">&#x27;strong&#x27;</span>).get_text()</span><br><span class="line">        link = news.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;피시 사랑 &#123;0&#125; : &#123;1&#125; &#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; 링크 : &#123;0&#125; &#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;http://www.ilovepc.co.kr&#x27;</span>+link))</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">            f.write(<span class="string">&#x27;ilovepc &#123;0&#125; : &#123;1&#125; \n\n&#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">        f.write(<span class="string">&#x27;\n\n\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kormedi</span>():</span></span><br><span class="line">    url = <span class="string">&quot;http://kormedi.com/healthnews/&quot;</span></span><br><span class="line">    res = urllib.request.urlopen(url)</span><br><span class="line">    source = res.read()</span><br><span class="line">    res.close()</span><br><span class="line">    soup = BeautifulSoup(source, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    soup = soup.find_all(<span class="string">&#x27;h2&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;title&#x27;</span>&#125;, limit=<span class="number">16</span>)</span><br><span class="line">    now = time.strftime(<span class="string">&#x27;%Y-%m-%d %H-%M&#x27;</span>, time.localtime(time.time()))</span><br><span class="line">    <span class="comment"># print(soup)</span></span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup):</span><br><span class="line">        data = news.find(<span class="string">&#x27;a&#x27;</span>).get_text().strip()</span><br><span class="line">        link = news.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;코메디 &#123;0&#125; : &#123;1&#125; &#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; 링크 : &#123;0&#125; &#x27;</span>.<span class="built_in">format</span>(link))</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">            f.write(<span class="string">&#x27;kormedi &#123;0&#125; : &#123;1&#125; \n\n&#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>, data))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/&#123;0&#125;_news.txt&#x27;</span>.<span class="built_in">format</span>(now), <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">        f.write(<span class="string">&#x27;\n\n\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  <span class="comment"># scrape_weather()라는 함수가 같은파일(A020_project.py)안에 있다면 실행하게</span></span><br><span class="line">    jtbc_news()            <span class="comment"># jtbc 뉴스</span></span><br><span class="line">    psy_cardnews()    <span class="comment"># 정신의학 카드뉴스</span></span><br><span class="line">    sciencetimes()    <span class="comment"># 과학 뉴스</span></span><br><span class="line">    ilovepc()         <span class="comment"># 피시사랑 뉴스</span></span><br><span class="line">    kormedi()         <span class="comment"># 코메디 뉴스</span></span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure>













</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-06-29T05:25:33.000Z" title="2021. 6. 29. 오후 2:25:33">2021-06-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-06-30T04:52:11.983Z" title="2021. 6. 30. 오후 1:52:11">2021-06-30</time></span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a></span><span class="level-item">14 minutes read (About 2131 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/06/29/A/A020_project/">A020_project</a></h1><div class="content"><p>사용 버전 - Python 3.9.5 64-bit</p>
<h1 id="프로젝트-웹-스크레핑을-통해-나만의-비서를-만들어-보자"><a href="#프로젝트-웹-스크레핑을-통해-나만의-비서를-만들어-보자" class="headerlink" title="프로젝트 : 웹 스크레핑을 통해 나만의 비서를 만들어 보자."></a>프로젝트 : 웹 스크레핑을 통해 나만의 비서를 만들어 보자.</h1><h2 id="조-건"><a href="#조-건" class="headerlink" title="[조 건]"></a>[조 건]</h2><h3 id="1-네이버에서-오늘-대구의-날씨를-가져온다"><a href="#1-네이버에서-오늘-대구의-날씨를-가져온다" class="headerlink" title="1. 네이버에서 오늘 대구의 날씨를 가져온다."></a>1. 네이버에서 오늘 대구의 날씨를 가져온다.</h3><h3 id="2-네이버에서-헤드라인-뉴스-3건을-가져온다"><a href="#2-네이버에서-헤드라인-뉴스-3건을-가져온다" class="headerlink" title="2. 네이버에서 헤드라인 뉴스 3건을 가져온다."></a>2. 네이버에서 헤드라인 뉴스 3건을 가져온다.</h3><h3 id="3-IT-뉴스-3건을-가져온다"><a href="#3-IT-뉴스-3건을-가져온다" class="headerlink" title="3. IT 뉴스 3건을 가져온다."></a>3. IT 뉴스 3건을 가져온다.</h3><h3 id="4-오늘의-영어-회화-지문을-가져온다-해커스-어학원"><a href="#4-오늘의-영어-회화-지문을-가져온다-해커스-어학원" class="headerlink" title="4. 오늘의 영어 회화 지문을 가져온다.(해커스 어학원)"></a>4. 오늘의 영어 회화 지문을 가져온다.(해커스 어학원)</h3><h2 id="출력-예시"><a href="#출력-예시" class="headerlink" title="[출력 예시]"></a>[출력 예시]</h2><h3 id="오늘의-날씨"><a href="#오늘의-날씨" class="headerlink" title="[ 오늘의 날씨]"></a>[ 오늘의 날씨]</h3><h3 id="맑음-어제보다-00도-높아요"><a href="#맑음-어제보다-00도-높아요" class="headerlink" title="맑음, 어제보다 00도 높아요"></a>맑음, 어제보다 00도 높아요</h3><h3 id="현재-00도-최저-00도-최고-00도"><a href="#현재-00도-최저-00도-최고-00도" class="headerlink" title="현재 00도 (최저 00도 / 최고 00도)"></a>현재 00도 (최저 00도 / 최고 00도)</h3><h3 id="오전-강수확률-00-오후-강수확률-00"><a href="#오전-강수확률-00-오후-강수확률-00" class="headerlink" title="오전 강수확률 00% / 오후 강수확률 00%"></a>오전 강수확률 00% / 오후 강수확률 00%</h3><h2 id="미세먼지-좋음"><a href="#미세먼지-좋음" class="headerlink" title="미세먼지(  ) 좋음"></a>미세먼지(  ) 좋음</h2><h2 id="헤드라인-뉴스"><a href="#헤드라인-뉴스" class="headerlink" title="[헤드라인 뉴스]"></a>[헤드라인 뉴스]</h2><h3 id="1-뉴스1제목"><a href="#1-뉴스1제목" class="headerlink" title="1. 뉴스1제목"></a>1. 뉴스1제목</h3><h3 id="링크-https-…"><a href="#링크-https-…" class="headerlink" title="( 링크 : https://…. )"></a>( 링크 : https://…. )</h3><h3 id="2-뉴스2제목"><a href="#2-뉴스2제목" class="headerlink" title="2. 뉴스2제목"></a>2. 뉴스2제목</h3><h3 id="링크-https-…-1"><a href="#링크-https-…-1" class="headerlink" title="( 링크 : https://…. )"></a>( 링크 : https://…. )</h3><h3 id="3-뉴스3제목"><a href="#3-뉴스3제목" class="headerlink" title="3. 뉴스3제목"></a>3. 뉴스3제목</h3><h3 id="링크-https-…-2"><a href="#링크-https-…-2" class="headerlink" title="( 링크 : https://…. )"></a>( 링크 : https://…. )</h3><h2 id="IT-뉴스"><a href="#IT-뉴스" class="headerlink" title="[IT 뉴스]"></a>[IT 뉴스]</h2><h3 id="1-뉴스1제목-1"><a href="#1-뉴스1제목-1" class="headerlink" title="1. 뉴스1제목"></a>1. 뉴스1제목</h3><h3 id="링크-https-…-3"><a href="#링크-https-…-3" class="headerlink" title="( 링크 : https://…. )"></a>( 링크 : https://…. )</h3><h3 id="2-뉴스2제목-1"><a href="#2-뉴스2제목-1" class="headerlink" title="2. 뉴스2제목"></a>2. 뉴스2제목</h3><h3 id="링크-https-…-4"><a href="#링크-https-…-4" class="headerlink" title="( 링크 : https://…. )"></a>( 링크 : https://…. )</h3><h3 id="3-뉴스3제목-1"><a href="#3-뉴스3제목-1" class="headerlink" title="3. 뉴스3제목"></a>3. 뉴스3제목</h3><h3 id="링크-https-…-5"><a href="#링크-https-…-5" class="headerlink" title="( 링크 : https://…. )"></a>( 링크 : https://…. )</h3><h2 id="오늘의-영어-회화"><a href="#오늘의-영어-회화" class="headerlink" title="[오늘의 영어 회화]"></a>[오늘의 영어 회화]</h2><h3 id="영어-지문"><a href="#영어-지문" class="headerlink" title="(영어 지문)"></a>(영어 지문)</h3><h3 id="kim-How-are-you"><a href="#kim-How-are-you" class="headerlink" title="kim : How are you?"></a>kim : How are you?</h3><h3 id="lee-fine"><a href="#lee-fine" class="headerlink" title="lee : fine!"></a>lee : fine!</h3><h3 id="한글-지문"><a href="#한글-지문" class="headerlink" title="(한글 지문)"></a>(한글 지문)</h3><h3 id="kim-어때"><a href="#kim-어때" class="headerlink" title="kim : 어때?"></a>kim : 어때?</h3><h3 id="lee-좋아"><a href="#lee-좋아" class="headerlink" title="lee : 좋아!"></a>lee : 좋아!</h3><h1 id="파이썬-기초-w3school-python-org-위키독스-점프투파이썬"><a href="#파이썬-기초-w3school-python-org-위키독스-점프투파이썬" class="headerlink" title="파이썬 기초 : w3school, python.org, 위키독스(점프투파이썬)"></a>파이썬 기초 : w3school, python.org, 위키독스(점프투파이썬)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 반복되는 부분을 함수로 생성</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_soup</span>(<span class="params">url, headers</span>):</span>         <span class="comment"># 필요한 매개변수를 넣어줘야함</span></span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    res.raise_for_status()</span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> soup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 날씨 wed / 온도 tem / 강수확률 rain / 미세먼지 fdust / 초미세먼지 ufdust</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_weather</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[오늘의 날씨]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;https://search.naver.com/search.naver?sm=tab_hty.top&amp;where=nexearch&amp;query=%EB%8C%80%EA%B5%AC%EB%82%A0%EC%94%A8&amp;oquery=%EB%82%A0%EC%94%A8&amp;tqi=h71ErlprvN8ss6l%2FnnCssssstk4-523554&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    <span class="comment"># res = requests.get(url, headers=headers)</span></span><br><span class="line">    <span class="comment"># res.raise_for_status()</span></span><br><span class="line">    <span class="comment"># soup = BeautifulSoup(res.text, &#x27;lxml&#x27;)</span></span><br><span class="line">    soup = create_soup(url, headers)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 맑음, 어제보다 0도 높아요</span></span><br><span class="line">    cast = soup.find(<span class="string">&#x27;p&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;cast_txt&#x27;</span>&#125;).get_text()</span><br><span class="line">    </span><br><span class="line">    curr_temp = soup.find(<span class="string">&#x27;p&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;info_temperature&#x27;</span>&#125;).get_text().replace(<span class="string">&#x27;도씨&#x27;</span>, <span class="string">&#x27;&#x27;</span>)      <span class="comment"># 현재온도</span></span><br><span class="line">    <span class="comment"># 가져온 텍스트중에 &#x27;도씨&#x27; 를 공백처리</span></span><br><span class="line">    </span><br><span class="line">    min_temp = soup.find(<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;min&#x27;</span>&#125;).get_text()   <span class="comment"># 최저온도</span></span><br><span class="line">    max_temp = soup.find(<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;max&#x27;</span>&#125;).get_text()   <span class="comment"># 최고온도</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 오전 오후 강수 확률</span></span><br><span class="line">    morning_rain_rate = soup.find(<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;point_time morning&#x27;</span>&#125;).get_text().strip() <span class="comment"># 오전 강수확률 / 공백제거</span></span><br><span class="line">    afternoon_rain_rate = soup.find(<span class="string">&#x27;span&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;point_time afternoon&#x27;</span>&#125;).get_text().strip() <span class="comment"># 오후 강수확률 / 공백제거</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 미세 먼지</span></span><br><span class="line">    dust = soup.find(<span class="string">&#x27;dl&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;indicator&#x27;</span>&#125;)</span><br><span class="line">    pm = dust.find(<span class="string">&#x27;dd&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;lv1&#x27;</span>&#125;).get_text()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(dust)</span></span><br><span class="line">    <span class="built_in">print</span>(cast)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;현재 &#123;0&#125; (최저 &#123;1&#125; / 최고 &#123;2&#125;)&#x27;</span>.<span class="built_in">format</span>(curr_temp, min_temp, max_temp))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;오전 &#123;0&#125; / 오후 &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(morning_rain_rate, afternoon_rain_rate))</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;미세먼지 &#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(pm))</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 헤드라인 뉴스</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_headline_news</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[헤드라인 뉴스]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;https://news.naver.com&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    <span class="comment"># res = requests.get(url, headers=headers)</span></span><br><span class="line">    <span class="comment"># res.raise_for_status()</span></span><br><span class="line">    <span class="comment"># soup = BeautifulSoup(res.text, &#x27;lxml&#x27;)</span></span><br><span class="line">    soup = create_soup(url, headers)</span><br><span class="line"></span><br><span class="line">    news_list = soup.find(<span class="string">&#x27;ul&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;hdline_article_list&#x27;</span>&#125;).find_all(<span class="string">&#x27;li&#x27;</span>, limit=<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># ul 테그의 hdline_article_list 클레스에서 가져온 것들중에 li테그에 속한것을 3개만 가져옴</span></span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(news_list):        <span class="comment"># 인덱스값 매기기 index는 번호를 매겨줌</span></span><br><span class="line">        title = news.find(<span class="string">&#x27;a&#x27;</span>).get_text().strip()</span><br><span class="line">        link = news.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;. &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(index + <span class="number">1</span>, title))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;   (  링크 : &#123;0&#125;  )&#x27;</span>.<span class="built_in">format</span>(url + link))</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line"><span class="comment"># IT뉴스</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_it_news</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[IT 뉴스]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;https://news.naver.com/main/list.nhn?mode=LS2D&amp;mid=shm&amp;sid1=105&amp;sid2=230&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    res.raise_for_status()</span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    news_list = soup.find(<span class="string">&#x27;ul&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;type06_headline&#x27;</span>&#125;).find_all(<span class="string">&#x27;li&#x27;</span>, limit=<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(news_list):</span><br><span class="line">        a_idx = <span class="number">0</span>       <span class="comment"># 임의의 변수 설정</span></span><br><span class="line">        img = news.find(<span class="string">&#x27;img&#x27;</span>)  <span class="comment"># img 라는 테그를 찾아서 img변수에 넣음</span></span><br><span class="line">        <span class="keyword">if</span> img:     <span class="comment"># img 테그가 나온다면</span></span><br><span class="line">            a_idx = <span class="number">1</span>   <span class="comment"># a 태그가 있으면 1번인 a 태그의 정보를 가져옴( 두번째 a 태그를 가져옴)</span></span><br><span class="line">        title = news.find_all(<span class="string">&#x27;a&#x27;</span>)[a_idx].get_text().strip()    <span class="comment"># 인덱스 값이 여러개이기 때문에 all로 검색해야함</span></span><br><span class="line">        link = news.find_all(<span class="string">&#x27;a&#x27;</span>)[a_idx][<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;. &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(index + <span class="number">1</span>, title))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;   (  링크 : &#123;0&#125;  )&#x27;</span>.<span class="built_in">format</span>(link))</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_english</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[오늘의 영어회화]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;https://www.hackers.co.kr/?c=s_eng/eng_contents/I_others_english&amp;keywd=haceng_submain_lnb_eng_I_others_english&amp;logger_kw=haceng_submain_lnb_eng_I_others_english&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    res.raise_for_status()</span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)   </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[영어 지문]&#x27;</span>)</span><br><span class="line">    sentences = soup.find_all(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;id&#x27;</span>:re.<span class="built_in">compile</span>(<span class="string">&#x27;^conv_kor_t&#x27;</span>)&#125;)</span><br><span class="line">    <span class="comment"># conv_kor_t2, conv_kor_t3 이런식으로 아이디의 이름이 다를경우</span></span><br><span class="line">    <span class="comment"># 정규 표현식인 re를 사용해 테그를 검색해서 자료 검출</span></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences[<span class="built_in">len</span>(sentences)//<span class="number">2</span>:]:   <span class="comment"># len(sentences)//2: = 4 ~ 끝까지(7)이 됨 //는 앞에 정수만 가져오는거</span></span><br><span class="line">        <span class="built_in">print</span>(sentence.get_text().strip())    </span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[한글 지문]&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences[:<span class="built_in">len</span>(sentences)//<span class="number">2</span>]:   <span class="comment"># :len(sentences)//2 = 처음부터 3까지</span></span><br><span class="line">        <span class="built_in">print</span>(sentence.get_text().strip())    </span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  <span class="comment"># scrape_weather()라는 함수가 같은파일(A020_project.py)안에 있다면 실행하도록 하는 코드</span></span><br><span class="line">    scrape_weather()        <span class="comment"># 오늘 날씨 정보 가져오기</span></span><br><span class="line">    scrape_headline_news()  <span class="comment"># 헤드라인 뉴스</span></span><br><span class="line">    scrape_it_news()          <span class="comment"># 아이티 뉴스</span></span><br><span class="line">    scrape_english()          <span class="comment"># 영어 회화</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="추가-내용"><a href="#추가-내용" class="headerlink" title="추가 내용"></a>추가 내용</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  다음 뉴스에서 3개 뉴스의 제목과 링크 가져오기</span></span><br><span class="line"><span class="comment"># 1. 제목...</span></span><br><span class="line"><span class="comment">#    링크...</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_daum_news</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[다음 헤드라인 뉴스]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;https://news.daum.net&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    res.raise_for_status()</span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    news_list = soup.find(<span class="string">&#x27;ul&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;list_headline&#x27;</span>&#125;).find_all(<span class="string">&#x27;li&#x27;</span>, limit=<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># ul 테그의 hdline_article_list 클레스에서 가져온 것들중에 li테그에 속한것을 3개만 가져옴</span></span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(news_list):        <span class="comment"># 인덱스값 매기기 index는 번호를 매겨줌</span></span><br><span class="line">        title = news.find(<span class="string">&#x27;a&#x27;</span>).get_text().strip()</span><br><span class="line">        link = news.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;. &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(index + <span class="number">1</span>, title))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;   (  링크 : &#123;0&#125;  )&#x27;</span>.<span class="built_in">format</span>(link))</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 다음 경제 뉴스에서 2개 뉴스의 제목과 링크 가져오기</span></span><br><span class="line"><span class="comment"># 1. 제목...</span></span><br><span class="line"><span class="comment">#    링크...</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_daum_economic_news</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[다음 경제 뉴스]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;https://news.daum.net/economic#1&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    res.raise_for_status()</span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    news_list = soup.find(<span class="string">&#x27;ul&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;list_mainnews&#x27;</span>&#125;).find_all(<span class="string">&#x27;li&#x27;</span>, limit=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># ul 테그의 hdline_article_list 클레스에서 가져온 것들중에 li테그에 속한것을 3개만 가져옴</span></span><br><span class="line">    <span class="keyword">for</span> index, news <span class="keyword">in</span> <span class="built_in">enumerate</span>(news_list):</span><br><span class="line">        a_idx = <span class="number">0</span>       <span class="comment"># 임의의 변수 설정</span></span><br><span class="line">        img = news.find(<span class="string">&#x27;img&#x27;</span>)  <span class="comment"># img 라는 테그를 찾아서 img변수에 넣음</span></span><br><span class="line">        <span class="keyword">if</span> img:     <span class="comment"># img 테그가 나온다면</span></span><br><span class="line">            a_idx = <span class="number">1</span>   <span class="comment"># a 태그가 있으면 1번인 a 태그의 정보를 가져옴( 두번째 a 태그를 가져옴)</span></span><br><span class="line">        title = news.find_all(<span class="string">&#x27;a&#x27;</span>)[a_idx].get_text().strip()    <span class="comment"># 인덱스 값이 여러개이기 때문에 all로 검색해야함</span></span><br><span class="line">        link = news.find_all(<span class="string">&#x27;a&#x27;</span>)[a_idx][<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;. &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(index + <span class="number">1</span>, title))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;   (  링크 : &#123;0&#125;  )&#x27;</span>.<span class="built_in">format</span>(link))</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 다음 게임에서 추천 게임 4개의 제목과 이미지 가져오기</span></span><br><span class="line"><span class="comment"># 1. 제목...</span></span><br><span class="line"><span class="comment">#    이미지</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_daum_game</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[다음 게임]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;http://game.daum.net&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    res.raise_for_status()</span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    game_list_pc = soup.find(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;area_pc&#x27;</span>&#125;).find_all(<span class="string">&#x27;li&#x27;</span>, limit=<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># ul 테그의 hdline_article_list 클레스에서 가져온 것들중에 li테그에 속한것을 3개만 가져옴</span></span><br><span class="line">    <span class="keyword">for</span> index, pc_game <span class="keyword">in</span> <span class="built_in">enumerate</span>(game_list_pc):        <span class="comment"># 인덱스값 매기기 index는 번호를 매겨줌</span></span><br><span class="line">        title = pc_game.find(<span class="string">&#x27;a&#x27;</span>).get_text().strip()</span><br><span class="line">        image_url = pc_game.find(<span class="string">&#x27;img&#x27;</span>)[<span class="string">&#x27;src&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;. &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(index + <span class="number">1</span>, title))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;   (  이미지 : &#123;0&#125;  )&#x27;</span>.<span class="built_in">format</span>(image_url))</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">        image_res = requests.get(image_url)</span><br><span class="line">        image_res.raise_for_status()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/A020_pcgame&#123;0&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>), <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 피씨게임 이미지 파일생성</span></span><br><span class="line">            f.write(image_res.content)</span><br><span class="line">        </span><br><span class="line">    game_list_m = soup.find(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;area_m&#x27;</span>&#125;).find_all(<span class="string">&#x27;li&#x27;</span>, limit=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># ul 테그의 hdline_article_list 클레스에서 가져온 것들중에 li테그에 속한것을 3개만 가져옴</span></span><br><span class="line">    <span class="keyword">for</span> index, m_game <span class="keyword">in</span> <span class="built_in">enumerate</span>(game_list_m):        <span class="comment"># 인덱스값 매기기 index는 번호를 매겨줌</span></span><br><span class="line">        title = m_game.find(<span class="string">&#x27;a&#x27;</span>).get_text().strip()</span><br><span class="line">        image_url = m_game.find(<span class="string">&#x27;img&#x27;</span>)[<span class="string">&#x27;src&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;. &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(index + <span class="number">1</span>, title))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;   (  이미지 : &#123;0&#125;  )&#x27;</span>.<span class="built_in">format</span>(image_url))</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">        image_res = requests.get(image_url)</span><br><span class="line">        image_res.raise_for_status()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./A/A020_mgame&#123;0&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(index+<span class="number">1</span>), <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 모바일 게임 이미지 파일생성</span></span><br><span class="line">            f.write(image_res.content)</span><br><span class="line"></span><br><span class="line">       </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 해커스에서 오늘의 한 줄 명언 가져오기</span></span><br><span class="line"><span class="comment"># (영어명언)</span></span><br><span class="line"><span class="comment"># (한글명언)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrape_wisesay</span>():</span>       </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[오늘의 명언]&#x27;</span>)</span><br><span class="line">    url = <span class="string">&#x27;https://www.hackers.co.kr/?c=s_eng/eng_contents/B_others_wisesay&amp;keywd=haceng_submain_lnb_eng_B_others_wisesay&amp;logger_kw=haceng_submain_lnb_eng_B_others_wisesay&#x27;</span></span><br><span class="line">    headers  = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    res.raise_for_status()</span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[영어 명언]&#x27;</span>)</span><br><span class="line">    sentence_eng = soup.find(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;text_en&#x27;</span>&#125;).get_text()</span><br><span class="line">    <span class="built_in">print</span>(sentence_eng)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[한글 명언]&quot;</span>)</span><br><span class="line">    sentence_ko = soup.find(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>:<span class="string">&#x27;text_ko&#x27;</span>&#125;).get_text()</span><br><span class="line">    <span class="built_in">print</span>(sentence_ko)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  <span class="comment"># scrape_weather()라는 함수가 같은파일(A020_project.py)안에 있다면 실행하도록 하는 코드</span></span><br><span class="line">    scrape_daum_news()          <span class="comment"># 다음 헤드라인 뉴스          </span></span><br><span class="line">    scrape_daum_economic_news()       <span class="comment"># 다음 경제 뉴스</span></span><br><span class="line">    scrape_daum_game()            <span class="comment"># 다음 게임</span></span><br><span class="line">    scrape_wisesay()              <span class="comment"># 오늘의 명언 영어회화</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/diablo.jpg" alt="LDH"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">LDH</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">102</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">40</p></a></div></div></nav></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://github.com/ldhjj77" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">MY Git Hub</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Error/"><span class="level-start"><span class="level-item">Error</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/HEXO/"><span class="level-start"><span class="level-item">HEXO</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Markdown/"><span class="level-start"><span class="level-item">Markdown</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Plotly/"><span class="level-start"><span class="level-item">Plotly</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">29</span></span></a></li><li><a class="level is-mobile" href="/categories/Tableau/"><span class="level-start"><span class="level-item">Tableau</span></span><span class="level-end"><span class="level-item tag">48</span></span></a></li><li><a class="level is-mobile" href="/categories/%ED%8F%AC%ED%8A%B8%ED%8F%B4%EB%A6%AC%EC%98%A4/"><span class="level-start"><span class="level-item">포트폴리오</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-01T05:46:59.074Z">2021-09-01</time></p><p class="title"><a href="/2021/09/01/hello-world/">Hello World</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-27T08:00:00.000Z">2021-08-27</time></p><p class="title"><a href="/2021/08/27/project_md/Tableau/T051_%EB%B6%84%EC%82%B0%ED%98%95%EC%B0%A8%ED%8A%B8_%EA%B5%AD%EA%B0%80%EB%B3%84%EC%97%B0%EA%B0%84%ED%9D%90%EB%A6%84/">T051_분산형차트_국가별연간흐름</a></p><p class="categories"><a href="/categories/Tableau/">Tableau</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-27T06:00:00.000Z">2021-08-27</time></p><p class="title"><a href="/2021/08/27/project_md/Tableau/T050_LAST%ED%95%A8%EC%88%98_%EC%B5%9C%EA%B7%BCN%EA%B0%9C%EC%9B%94%EB%A7%A4%EC%B6%9C/">T050_LAST함수_최근N개월매출</a></p><p class="categories"><a href="/categories/Tableau/">Tableau</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-27T05:00:00.000Z">2021-08-27</time></p><p class="title"><a href="/2021/08/27/project_md/Tableau/T049_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%B0%EA%B2%B0_Union_%EC%9D%B4%EC%9D%B5%EA%B3%BC%ED%95%A0%EC%9D%B8_%EC%83%81%EA%B4%80%EA%B4%80%EA%B3%84/">T049_데이터연결_Union_이익과할인_상관관계</a></p><p class="categories"><a href="/categories/Tableau/">Tableau</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-27T03:00:00.000Z">2021-08-27</time></p><p class="title"><a href="/2021/08/27/project_md/Tableau/T048_LAST%ED%95%A8%EC%88%98%ED%99%9C%EC%9A%A9_%EB%A7%88%EC%A7%80%EB%A7%89%EB%82%A0%EC%A7%9C%EA%B8%B0%EC%A4%80_%EC%84%B1%EC%9E%A5%EC%9C%A8/">T048_LAST함수활용_마지막날짜기준_성장율</a></p><p class="categories"><a href="/categories/Tableau/">Tableau</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">September 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">August 2021</span></span><span class="level-end"><span class="level-item tag">52</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">July 2021</span></span><span class="level-end"><span class="level-item tag">28</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/06/"><span class="level-start"><span class="level-item">June 2021</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/A/"><span class="tag">A</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/B/"><span class="tag">B</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BeautifulSoup/"><span class="tag">BeautifulSoup</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CatBoost/"><span class="tag">CatBoost</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/E/"><span class="tag">E</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Keras/"><span class="tag">Keras</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LightGBM/"><span class="tag">LightGBM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Module/"><span class="tag">Module</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Numpy/"><span class="tag">Numpy</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PDF/"><span class="tag">PDF</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PPT/"><span class="tag">PPT</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tableau/"><span class="tag">Tableau</span><span class="tag">52</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XGBoost/"><span class="tag">XGBoost</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/chart-studio/"><span class="tag">chart_studio</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/class/"><span class="tag">class</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/error/"><span class="tag">error</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/exception/"><span class="tag">exception</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/for/"><span class="tag">for</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/info/"><span class="tag">info</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/inheritance/"><span class="tag">inheritance</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kaggle/"><span class="tag">kaggle</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/md/"><span class="tag">md</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pandas/"><span class="tag">pandas</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pycaret/"><span class="tag">pycaret</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/re/"><span class="tag">re</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/selenium/"><span class="tag">selenium</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/time/"><span class="tag">time</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/titanic/"><span class="tag">titanic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/translator/"><span class="tag">translator</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/webdriver/"><span class="tag">webdriver</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B8%B0%EB%8A%A5/"><span class="tag">기능</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B0%B0%EC%97%B4%EC%83%9D%EC%84%B1/"><span class="tag">배열생성</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B0%B0%EC%97%B4%EC%9D%B8%EC%87%84/"><span class="tag">배열인쇄</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B2%94%EC%9A%A9%ED%95%A8%EC%88%98/"><span class="tag">범용함수</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%8A%AC%EB%9D%BC%EC%9D%B4%EC%8B%B1/"><span class="tag">슬라이싱</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%98%88%EC%99%B8%EC%B2%98%EB%A6%AC/"><span class="tag">예외처리</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%98%A4%EB%9D%BC%ED%81%B4/"><span class="tag">오라클</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%9D%B8%EB%8D%B1%EC%8B%B1/"><span class="tag">인덱싱</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%81%AC%EB%A1%A4%EB%A7%81/"><span class="tag">크롤링</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%8C%8C%EC%9D%BC%EC%83%9D%EC%84%B1/"><span class="tag">파일생성</span><span class="tag">3</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/diablo.jpg" alt="Hexo" height="28"></a><p class="is-size-7"><span>&copy; 2021 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "classic",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>